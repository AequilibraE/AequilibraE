{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sioux Falls example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fldr = 'D:/release/Sample models/sioux_falls_2020_02_15'\n",
    "\n",
    "# remove the comments for the lines below to run the Chicago model example instead\n",
    "# fldr = 'D:/release/Sample models/Chicago_2020_02_15'\n",
    "# proj_name = 'chicagomodel.sqlite'\n",
    "\n",
    "dt_fldr = '0_tntp_data'\n",
    "prj_fldr = '1_project'\n",
    "new_proj_folder = '1_project_temp'\n",
    "\n",
    "skm_fldr = '2_skim_results'\n",
    "assg_fldr = '4_assignment_results'\n",
    "dstr_fldr = '5_distribution_results'\n",
    "frcst_fldr = '6_forecast'\n",
    "ftr_fldr = '7_future_year_assignment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We copy the project to a different folder so we don't overwrite things like the matrix table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/release/Sample models/sioux_falls_2020_02_15\\\\1_project_temp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copytree, rmtree\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "if isdir(join(fldr, new_proj_folder)):\n",
    "    rmtree(join(fldr, new_proj_folder))\n",
    "\n",
    "copytree(join(fldr, prj_fldr), join(fldr, new_proj_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from aequilibrae.project import Project\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "project = Project()\n",
    "project.load(join(fldr, new_proj_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from aequilibrae.paths import PathResults, path_computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# we build all graphs\n",
    "project.network.build_graphs()\n",
    "# We get warnings that several fields in the project are filled with NaNs.  Which is true, but we won't use those fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# we grab the graph for cars\n",
    "graph = project.network.graphs['c']\n",
    "\n",
    "# let's say we want to minimize distance\n",
    "graph.set_graph('distance')\n",
    "\n",
    "# And will skim time and distance while we are at it\n",
    "graph.set_skimming(['free_flow_time', 'distance'])\n",
    "\n",
    "# And we will allow paths to be compute going through other centroids/centroid connectors\n",
    "# required for the Sioux Falls network, as all nodes are centroids\n",
    "graph.set_blocked_centroid_flows(False)\n",
    "\n",
    "# instantiate a path results object and prepare it to work with the graph\n",
    "res = PathResults()\n",
    "res.prepare(graph)\n",
    "\n",
    "# compute a path from node 2 to 13\n",
    "path_computation(2, 13, graph, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  3, 12, 13], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the sequence of nodes we traverse\n",
    "res.path_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  2,  7, 37], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the link sequence we traverse\n",
    "res.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  6., 10., 14., 17.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the mileposts for our sequence of nodes\n",
    "res.milepost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# If we want to compute the path for a different destination and same origin, we can just do this\n",
    "# It is way faster when you have large networks\n",
    "res.update_trace(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.path_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from aequilibrae.matrix import AequilibraeData, AequilibraeMatrix\n",
    "from aequilibrae.paths import NetworkSkimming, SkimResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# from before\n",
    "graph = project.network.graphs['c'] # we grab the graph for cars\n",
    "graph.set_graph('free_flow_time') # let's say we want to minimize time\n",
    "graph.set_skimming(['free_flow_time', 'distance']) # And will skim time and distance\n",
    "graph = project.network.graphs['c'] # we grab the graph for cars\n",
    "graph.set_blocked_centroid_flows(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# And run the skimming\n",
    "skm = NetworkSkimming(graph)\n",
    "skm.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[[ 0.,  0.],\n",
       "         [ 6.,  6.],\n",
       "         [ 4.,  4.],\n",
       "         ...,\n",
       "         [20., 20.],\n",
       "         [17., 17.],\n",
       "         [15., 15.]],\n",
       "\n",
       "        [[ 6.,  6.],\n",
       "         [ 0.,  0.],\n",
       "         [10., 10.],\n",
       "         ...,\n",
       "         [21., 21.],\n",
       "         [23., 23.],\n",
       "         [21., 21.]],\n",
       "\n",
       "        [[ 4.,  4.],\n",
       "         [10., 10.],\n",
       "         [ 0.,  0.],\n",
       "         ...,\n",
       "         [16., 16.],\n",
       "         [13., 13.],\n",
       "         [11., 11.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[20., 20.],\n",
       "         [21., 21.],\n",
       "         [16., 16.],\n",
       "         ...,\n",
       "         [ 0.,  0.],\n",
       "         [ 4.,  4.],\n",
       "         [ 5.,  5.]],\n",
       "\n",
       "        [[17., 17.],\n",
       "         [23., 23.],\n",
       "         [13., 13.],\n",
       "         ...,\n",
       "         [ 4.,  4.],\n",
       "         [ 0.,  0.],\n",
       "         [ 2.,  2.]],\n",
       "\n",
       "        [[15., 15.],\n",
       "         [21., 21.],\n",
       "         [11., 11.],\n",
       "         ...,\n",
       "         [ 5.,  5.],\n",
       "         [ 2.,  2.],\n",
       "         [ 0.,  0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result is an AequilibraEMatrix object\n",
    "skims = skm.results.skims\n",
    "\n",
    "# Which we can manipute directly from its temp file, if we wish\n",
    "skims.matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[ 0.,  6.,  4.,  8., 10., 11., 16., 13., 15., 18., 14.,  8., 11.,\n",
       "         18., 23., 18., 20., 18., 22., 22., 18., 20., 17., 15.],\n",
       "        [ 6.,  0., 10., 11.,  9.,  5., 10.,  7., 14., 16., 17., 14., 17.,\n",
       "         21., 19., 12., 14., 12., 16., 16., 22., 21., 23., 21.],\n",
       "        [ 4., 10.,  0.,  4.,  6., 10., 15., 12., 11., 14., 10.,  4.,  7.,\n",
       "         14., 19., 17., 19., 17., 21., 20., 14., 16., 13., 11.],\n",
       "        [ 8., 11.,  4.,  0.,  2.,  6., 11.,  8.,  7., 10.,  6.,  8., 11.,\n",
       "         10., 15., 13., 15., 13., 17., 17., 18., 18., 14., 15.],\n",
       "        [10.,  9.,  6.,  2.,  0.,  4.,  9.,  6.,  5.,  8.,  8., 10., 13.,\n",
       "         12., 14., 11., 13., 11., 15., 15., 19., 17., 16., 17.],\n",
       "        [11.,  5., 10.,  6.,  4.,  0.,  5.,  2.,  9., 11., 12., 14., 17.,\n",
       "         16., 14.,  7.,  9.,  7., 11., 11., 17., 16., 20., 20.],\n",
       "        [16., 10., 15., 11.,  9.,  5.,  0.,  3., 12.,  9., 14., 19., 19.,\n",
       "         17., 12.,  5.,  7.,  2.,  9.,  6., 12., 11., 15., 15.],\n",
       "        [13.,  7., 12.,  8.,  6.,  2.,  3.,  0., 10.,  9., 14., 16., 19.,\n",
       "         17., 12.,  5.,  7.,  5.,  9.,  9., 15., 14., 18., 18.],\n",
       "        [15., 14., 11.,  7.,  5.,  9., 12., 10.,  0.,  3.,  8., 14., 17.,\n",
       "         12.,  9.,  7.,  9., 10., 11., 14., 14., 12., 16., 17.],\n",
       "        [18., 16., 14., 10.,  8., 11.,  9.,  9.,  3.,  0.,  5., 11., 14.,\n",
       "          9.,  6.,  4.,  6.,  7.,  8., 11., 11.,  9., 13., 14.],\n",
       "        [14., 17., 10.,  6.,  8., 12., 14., 14.,  8.,  5.,  0.,  6.,  9.,\n",
       "          4.,  9.,  9., 11., 12., 12., 16., 13., 12.,  8., 10.],\n",
       "        [ 8., 14.,  4.,  8., 10., 14., 19., 16., 14., 11.,  6.,  0.,  3.,\n",
       "         10., 15., 15., 17., 18., 18., 16., 10., 12.,  9.,  7.],\n",
       "        [11., 17.,  7., 11., 13., 17., 19., 19., 17., 14.,  9.,  3.,  0.,\n",
       "         10., 12., 18., 17., 17., 15., 13.,  7.,  9.,  6.,  4.],\n",
       "        [18., 21., 14., 10., 12., 16., 17., 17., 12.,  9.,  4., 10., 10.,\n",
       "          0.,  5., 12., 10., 15.,  8., 12.,  9.,  8.,  4.,  6.],\n",
       "        [23., 19., 19., 15., 14., 14., 12., 12.,  9.,  6.,  9., 15., 12.,\n",
       "          5.,  0.,  7.,  5., 10.,  3.,  7.,  5.,  3.,  7.,  8.],\n",
       "        [18., 12., 17., 13., 11.,  7.,  5.,  5.,  7.,  4.,  9., 15., 18.,\n",
       "         12.,  7.,  0.,  2.,  3.,  4.,  7., 12., 10., 14., 15.],\n",
       "        [20., 14., 19., 15., 13.,  9.,  7.,  7.,  9.,  6., 11., 17., 17.,\n",
       "         10.,  5.,  2.,  0.,  5.,  2.,  6., 10.,  8., 12., 13.],\n",
       "        [18., 12., 17., 13., 11.,  7.,  2.,  5., 10.,  7., 12., 18., 17.,\n",
       "         15., 10.,  3.,  5.,  0.,  7.,  4., 10.,  9., 13., 13.],\n",
       "        [22., 16., 21., 17., 15., 11.,  9.,  9., 11.,  8., 12., 18., 15.,\n",
       "          8.,  3.,  4.,  2.,  7.,  0.,  4.,  8.,  6., 10., 11.],\n",
       "        [22., 16., 20., 17., 15., 11.,  6.,  9., 14., 11., 16., 16., 13.,\n",
       "         12.,  7.,  7.,  6.,  4.,  4.,  0.,  6.,  5.,  9.,  9.],\n",
       "        [18., 22., 14., 18., 19., 17., 12., 15., 14., 11., 13., 10.,  7.,\n",
       "          9.,  5., 12., 10., 10.,  8.,  6.,  0.,  2.,  5.,  3.],\n",
       "        [20., 21., 16., 18., 17., 16., 11., 14., 12.,  9., 12., 12.,  9.,\n",
       "          8.,  3., 10.,  8.,  9.,  6.,  5.,  2.,  0.,  4.,  5.],\n",
       "        [17., 23., 13., 14., 16., 20., 15., 18., 16., 13.,  8.,  9.,  6.,\n",
       "          4.,  7., 14., 12., 13., 10.,  9.,  5.,  4.,  0.,  2.],\n",
       "        [15., 21., 11., 15., 17., 20., 15., 18., 17., 14., 10.,  7.,  4.,\n",
       "          6.,  8., 15., 13., 13., 11.,  9.,  3.,  5.,  2.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ore access each matrix\n",
    "skims.free_flow_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save it to the project if we want\n",
    "skm.save_to_project('base_skims')\n",
    "\n",
    "# We can also retrieve this skim record to write something to its description\n",
    "matrices = project.matrices\n",
    "mat_record = matrices.get_record('base_skims')\n",
    "mat_record.description = 'minimized FF travel time while also skimming distance'\n",
    "mat_record.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic assignment with skimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from aequilibrae.matrix import AequilibraeMatrix\n",
    "from aequilibrae.paths import TrafficAssignment, TrafficClass\n",
    "from aequilibrae import logger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# from before\n",
    "graph = project.network.graphs['c'] # we grab the graph for cars\n",
    "graph.set_graph('free_flow_time') # let's say we want to minimize time\n",
    "graph.set_skimming(['free_flow_time', 'distance']) # And will skim time and distance\n",
    "graph.set_blocked_centroid_flows(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Because assignment takes a long time, we want the log to be shown here\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter(\"%(asctime)s;%(name)s;%(levelname)s ; %(message)s\")\n",
    "stdout_handler.setFormatter(formatter)\n",
    "logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demand = AequilibraeMatrix()\n",
    "demand.load(join(fldr, dt_fldr, 'demand.omx'))\n",
    "demand.computational_view(['matrix']) # We will only assign one user class stored as 'matrix' inside the OMX file\n",
    "\n",
    "assig = TrafficAssignment()\n",
    "\n",
    "# Creates the assignment class\n",
    "assigclass = TrafficClass(graph, demand)\n",
    "\n",
    "# The first thing to do is to add at list of traffic classes to be assigned\n",
    "assig.add_class(assigclass)\n",
    "# assig.set_classes([assigclass])\n",
    "\n",
    "assig.set_vdf(\"BPR\")  # This is not case-sensitive # Then we set the volume delay function\n",
    "\n",
    "assig.set_vdf_parameters({\"alpha\": \"b\", \"beta\": \"power\"}) # And its parameters\n",
    "\n",
    "assig.set_capacity_field(\"capacity\") # The capacity and free flow travel times as they exist in the graph\n",
    "assig.set_time_field(\"free_flow_time\")\n",
    "\n",
    "# And the algorithm we want to use to assign\n",
    "assig.set_algorithm('bfw')\n",
    "\n",
    "# since I haven't checked the parameters file, let's make sure convergence criteria is good\n",
    "assig.max_iter = 1000\n",
    "assig.rgap_target = 0.001\n",
    "\n",
    "assig.execute() # we then execute the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convergence report is easy to see\n",
    "import pandas as pd\n",
    "convergence_report = assig.report()\n",
    "convergence_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = assig.results()\n",
    "volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# The link flows are easy to export.\n",
    "# we do so for csv and AequilibraEData\n",
    "assig.save_results('tutorial_ime_ano_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# the skims are easy to get.\n",
    "\n",
    "# The blended one are here\n",
    "avg_skims = assigclass.results.skims\n",
    "\n",
    "# The ones for the last iteration are here\n",
    "last_skims = assigclass._aon_results.skims\n",
    "\n",
    "# Assembling a single final skim file can be done like this\n",
    "# We will want only the time for the last iteration and the distance averaged out for all iterations\n",
    "kwargs = {'file_name': join(fldr,assg_fldr, 'skims.aem'),\n",
    "          'zones': graph.num_zones,\n",
    "          'matrix_names': ['time_final', 'distance_blended']}\n",
    "\n",
    "# Create the matrix file\n",
    "out_skims = AequilibraeMatrix()\n",
    "out_skims.create_empty(**kwargs)\n",
    "out_skims.index[:] = avg_skims.index[:]\n",
    "\n",
    "# Transfer the data\n",
    " # The names of the skims are the name of the fields\n",
    "out_skims.matrix['time_final'][:,:] = last_skims.matrix['free_flow_time'][:,:]\n",
    "# It is CRITICAL to assign the matrix values using the [:,:]\n",
    "out_skims.matrix['distance_blended'][:,:] = avg_skims.matrix['distance'][:,:]\n",
    "\n",
    "out_skims.matrices.flush() # Make sure that all data went to the disk\n",
    "\n",
    "# Export to OMX as well\n",
    "out_skims.export(join(fldr,assg_fldr, 'skims.omx'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "\n",
    "We will calibrate synthetic gravity models using the skims for TIME that we just generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aequilibrae.distribution import GravityCalibration\n",
    "from aequilibrae.matrix import AequilibraeMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# We need the demand\n",
    "demand = AequilibraeMatrix()\n",
    "demand.load(join(fldr, dt_fldr, 'demand.omx'))\n",
    "\n",
    "# And the skims\n",
    "imped = AequilibraeMatrix()\n",
    "imped.load(join(fldr,assg_fldr, 'skims.aem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# But before using the data, let's get some impedance for the intrazonals\n",
    "# Let's assume it is 75% of the closest zone\n",
    "\n",
    "# If we run the code below more than once, we will be overwriting the diagonal values with non-sensical data\n",
    "# so let's zero it first\n",
    "np.fill_diagonal(imped.matrix['time_final'], 0)\n",
    "\n",
    "# We compute it with a little bit of NumPy magic\n",
    "intrazonals = np.amin(imped.matrix['time_final'], where=imped.matrix['time_final']>0, initial=imped.matrix['time_final'].max(), axis=1)\n",
    "intrazonals *= 0.75\n",
    "\n",
    "# Then we fill in the impedance matrix\n",
    "np.fill_diagonal(imped.matrix['time_final'], intrazonals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# We set the matrices forbeing used in computation\n",
    "imped.computational_view(['time_final'])\n",
    "demand.computational_view(['matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from math import log10, floor\n",
    "def plot_tlfd(demand, skim, name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    b = floor(log10(skim.shape[0]) * 10)\n",
    "    n, bins, patches = plt.hist(np.nan_to_num(skim.flatten(),0), bins = b, weights=np.nan_to_num(demand.flatten()), density=False, facecolor='g', alpha=0.75)\n",
    "\n",
    "    plt.xlabel('Trip length')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Trip-length frequency distribution')\n",
    "    plt.savefig(name, format=\"png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for function in ['power', 'expo']:\n",
    "    model = GravityCalibration(matrix=demand, impedance=imped, function=function, nan_as_zero=True)\n",
    "    model.calibrate()\n",
    "    \n",
    "    # we save the model\n",
    "    model.model.save(join(fldr, dstr_fldr, f'{function}_model.mod'))\n",
    "    \n",
    "    # We save a trip length frequency distribution image\n",
    "    plot_tlfd(model.result_matrix.matrix_view, imped.matrix_view,join(fldr, dstr_fldr, f'{function}_tfld.png') )\n",
    "    \n",
    "    # We can save the result of applying the model as well\n",
    "    # we can also save the calibration report\n",
    "    with open(join(fldr, dstr_fldr, f'{function}_convergence.log'), 'w') as otp:\n",
    "        for r in  model.report:\n",
    "            otp.write(r+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# We save a trip length frequency distribution image\n",
    "plot_tlfd(demand.matrix_view, imped.matrix_view,join(fldr, dstr_fldr, 'demand_tfld.png') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast\n",
    "\n",
    "* We create a set of *'future'* vectors using some random growth factors\n",
    "* We apply the model for inverse power, as the TFLD seems to be a better fit for the actual one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from aequilibrae.distribution import Ipf, GravityApplication, SyntheticGravityModel, Ipf\n",
    "from aequilibrae.matrix import AequilibraeData, AequilibraeMatrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# We compute the vectors from our matrix\n",
    "mat = AequilibraeMatrix()\n",
    "\n",
    "mat.load(join(fldr, dt_fldr, 'demand.omx'))\n",
    "mat.computational_view()\n",
    "origins = np.sum(mat.matrix_view, axis=1)\n",
    "destinations = np.sum(mat.matrix_view, axis=0)\n",
    "\n",
    "args = {'file_path':join(fldr,  frcst_fldr, 'synthetic_future_vector.aed'),\n",
    "        \"entries\": mat.zones, \n",
    "        \"field_names\": [\"origins\", \"destinations\"],\n",
    "    \"data_types\": [np.float64, np.float64], \n",
    "        \"memory_mode\": False}\n",
    "\n",
    "vectors = AequilibraeData()\n",
    "vectors.create_empty(**args)\n",
    "\n",
    "vectors.index[:] =mat.index[:]\n",
    "\n",
    "# Then grow them with some random growth between 0 and 10% - Plus balance them\n",
    "vectors.origins[:] = origins * (1+ np.random.rand(vectors.entries)/10)\n",
    "vectors.destinations[:] = destinations * (1+ np.random.rand(vectors.entries)/10)\n",
    "vectors.destinations *= vectors.origins.sum()/vectors.destinations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Impedance \n",
    "imped = AequilibraeMatrix()\n",
    "imped.load(join(fldr,assg_fldr, 'skims.aem'))\n",
    "imped.computational_view(['time_final'])\n",
    "\n",
    "# We want the main diagonal to be zero\n",
    "np.fill_diagonal(imped.matrix_view, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for function in ['power', 'expo']:\n",
    "    model = SyntheticGravityModel()\n",
    "    model.load(join(fldr, dstr_fldr, f'{function}_model.mod'))\n",
    "\n",
    "    outmatrix = join(fldr,frcst_fldr, f'demand_{function}_model.aem') \n",
    "    apply = GravityApplication()\n",
    "    args = {\"impedance\": imped,\n",
    "            \"rows\": vectors,\n",
    "            \"row_field\": \"origins\",\n",
    "            \"model\": model,\n",
    "            \"columns\": vectors,\n",
    "            \"column_field\": \"destinations\",\n",
    "            \"output\": outmatrix,\n",
    "            \"nan_as_zero\":True\n",
    "            }\n",
    "\n",
    "    gravity = GravityApplication(**args)\n",
    "    gravity.apply()\n",
    "\n",
    "    #We get the output matrix and save it to OMX too\n",
    "    resm = AequilibraeMatrix()\n",
    "    resm.load(outmatrix)\n",
    "    resm.export(join(fldr,frcst_fldr, f'demand_{function}_model.omx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now run IPF for the future vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "demand = AequilibraeMatrix()\n",
    "demand.load(join(fldr, dt_fldr, 'demand.omx'))\n",
    "demand.computational_view()\n",
    "\n",
    "args = {'matrix': demand,\n",
    "        'rows': vectors,\n",
    "        'columns': vectors,\n",
    "        'column_field': \"destinations\",\n",
    "        'row_field': \"origins\",\n",
    "        'nan_as_zero': True}\n",
    "\n",
    "ipf = Ipf(**args)\n",
    "ipf.fit()\n",
    "\n",
    "output = AequilibraeMatrix()\n",
    "output.load(ipf.output.file_path)\n",
    "\n",
    "output.export(join(fldr,frcst_fldr, 'demand_ipf.aem'))\n",
    "output.export(join(fldr,frcst_fldr, 'demand_ipf.omx'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future traffic assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from aequilibrae.matrix import AequilibraeMatrix\n",
    "from aequilibrae.paths import TrafficAssignment, TrafficClass\n",
    "from aequilibrae import logger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "logger.info('\\n\\n\\n TRAFFIC ASSIGNMENT FOR FUTURE YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# from before\n",
    "graph = project.network.graphs['c'] # we grab the graph for cars\n",
    "graph.set_graph('free_flow_time') # let's say we want to minimize time\n",
    "graph.set_skimming(['free_flow_time', 'distance']) # And will skim time and distance\n",
    "graph.set_blocked_centroid_flows(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's use the IPF matrix\n",
    "demand = AequilibraeMatrix()\n",
    "demand.load(join(fldr, frcst_fldr, 'demand_ipf.omx'))\n",
    "demand.computational_view() # There is only one matrix there, so don;t even worry about its core name\n",
    "\n",
    "assig = TrafficAssignment()\n",
    "\n",
    "# Creates the assignment class\n",
    "assigclass = TrafficClass(graph, demand)\n",
    "\n",
    "# The first thing to do is to add at list of traffic classes to be assigned\n",
    "assig.add_class(assigclass)\n",
    "\n",
    "assig.set_vdf(\"BPR\")  # This is not case-sensitive # Then we set the volume delay function\n",
    "\n",
    "assig.set_vdf_parameters({\"alpha\": \"b\", \"beta\": \"power\"}) # And its parameters\n",
    "\n",
    "assig.set_capacity_field(\"capacity\") # The capacity and free flow travel times as they exist in the graph\n",
    "assig.set_time_field(\"free_flow_time\")\n",
    "\n",
    "# And the algorithm we want to use to assign\n",
    "assig.set_algorithm('bfw')\n",
    "\n",
    "# since I haven't checked the parameters file, let's make sure convergence criteria is good\n",
    "assig.max_iter = 1000\n",
    "assig.rgap_target = 0.001\n",
    "\n",
    "assig.execute() # we then execute the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# The link flows are easy to export.\n",
    "# we do so for csv and AequilibraEData\n",
    "assig.save_results('tutorial_ime_futuro')\n",
    "\n",
    "# the skims are easy to get.\n",
    "\n",
    "# The blended one are here\n",
    "avg_skims = assigclass.results.skims\n",
    "\n",
    "# The ones for the last iteration are here\n",
    "last_skims = assigclass._aon_results.skims\n",
    "\n",
    "# Assembling a single final skim file can be done like this\n",
    "# We will want only the time for the last iteration and the distance averaged out for all iterations\n",
    "kwargs = {'file_name': join(fldr,ftr_fldr, 'future_skims.aem'),\n",
    "          'zones': graph.num_zones,\n",
    "          'matrix_names': ['time_final', 'distance_blended']}\n",
    "\n",
    "# Create the matrix file\n",
    "out_skims = AequilibraeMatrix()\n",
    "out_skims.create_empty(**kwargs)\n",
    "out_skims.index[:] = avg_skims.index[:]\n",
    "\n",
    "# Transfer the data\n",
    " # The names of the skims are the name of the fields\n",
    "out_skims.matrix['time_final'][:,:] = last_skims.matrix['free_flow_time'][:,:]\n",
    "# It is CRITICAL to assign the matrix values using the [:,:]\n",
    "out_skims.matrix['distance_blended'][:,:] = avg_skims.matrix['distance'][:,:]\n",
    "\n",
    "out_skims.matrices.flush() # Make sure that all data went to the disk\n",
    "\n",
    "# Export to OMX as well\n",
    "out_skims.export(join(fldr,ftr_fldr, 'future_skims.omx'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ''\n",
    "if a:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes[~(volumes.Congested_Time_AB>5) & ~(volumes.Congested_Time_Max<8)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
